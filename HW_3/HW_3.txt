import os, sys
import numpy as np
import pandas as pd

# ============================================================
# Imports & Constants
# ============================================================
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Local Imports
from utils.orbital_element_conversions.oe_conversions import orbital_elements_to_inertial
from resources.constants import MU_EARTH, J2, J3, R_EARTH
from utils.filters.ekf_class import EKF
from utils.plotting.post_process import post_process

# Output directory for plots
output_dir = 'HW_3/plots'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# ============================================================
# Main Execution
# ============================================================
# 1. Initial State Deviation & Covariances
# ----------------------------------------
# Deviation added to truth to create the initial estimate
x_0 = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3])

# Initial Covariance (P0)
P0 = np.diag([1, 1, 1, 1e-3, 1e-3, 1e-3])**2

# Measurement Noise (Rk): [Range (km^2), Range-Rate (km/s)^2]
Rk = np.diag([1e-6, 1e-12])

# Process noise (SNC implementation)
sigma_a = 1e-8 # convert to km/s^2 for consistency with state units
Q_psd = sigma_a**2 * np.eye(3)


# 2. Setup Reference Trajectory (The "Truth" or Linearization Point)
# -----------------------------------------------------------------
# Initial Truth State (orbital elements -> inertial)
r0, v0 = orbital_elements_to_inertial(10000, 0.001, 40, 80, 40, 0, units='deg')
Phi0 = np.eye(6).flatten()

# Initial State Vector for Integrator: [Pos, Vel, STM]
X_0 = np.concatenate([r0 + x_0[:3], v0 + x_0[3:], Phi0])

# Load Measurements
obs = pd.read_csv(fr'data\measurements_2a_noisy.csv')
time_eval = obs['Time(s)'].values

# Filter arguments
coeffs = np.array([MU_EARTH, J2, 0])

# We pack all Process Noise settings here for compute_q_discrete
options = {
    'coeffs': coeffs,
    'abs_tol': 1e-10,
    'rel_tol': 1e-10,
    'bootstrap_steps': 500,  # Number of initial steps to run in LKF mode
    
    # Process Noise Settings
    'method': 'SNC',          # Use State Noise Compensation
    'frame_type': 'RIC',      # Frame to apply noise (ECI or RIC)
    'Q_cont': Q_psd,          # Continuous PSD matrix
    'threshold': 10.0,       # Max dt threshold
    'B': None                 # Not used for SNC
}

# Run the Filter
ekf_filter = EKF(n_states=6)

# Key Fix: Q is now inside 'options', removed from function arguments
results = ekf_filter.run(
    obs=obs,
    X_0=X_0,
    x_0=x_0,
    P0=P0,
    Rk=Rk,
    options=options
)


# Run post-processing
post_options = {
    'truth_traj_file': r'data\problem_2a_traj.csv',
    'save_to_timestamped_folder': True,
    'data_mask_idx': 500,
    'plot_state_errors': True,
    'plot_state_deviation': True,
    'plot_postfit_residuals': True,
    'plot_prefit_residuals': True,
    'plot_residual_comparison': True,
    'plot_covariance_trace': True,
    'plot_filter_consistency': True,
    'plot_covariance_ellipsoid': True,
    'plot_nis_metric': True
}

post_process(results, obs, post_options)

import os, sys
import numpy as np
import pandas as pd

# ============================================================
# Imports & Constants
# ============================================================
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Local Imports
from utils.orbital_element_conversions.oe_conversions import orbital_elements_to_inertial
from resources.constants import MU_EARTH, J2, J3, R_EARTH
from utils.filters.lkf_class import LKF
from utils.plotting.post_process import post_process

# ============================================================
# Main Execution
# ============================================================
# Initial State Deviation & Covariances
x_0 = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3])
P0 = np.diag([1, 1, 1, 1e-3, 1e-3, 1e-3])**2
Rk = np.diag([1e-6, 1e-12])

# Initial Truth State (without deviation)
r0, v0 = orbital_elements_to_inertial(10000, 0.001, 40, 80, 40, 0, units='deg')
Phi0 = np.eye(6).flatten()

# Propagate the reference trajectory (truth plus deviation)
X_0 = np.concatenate([r0+x_0[:3], v0+x_0[3:], Phi0])

# Load Measurements
obs = pd.read_csv(fr'data\measurements_2a_noisy.csv')
time_eval = obs['Time(s)'].values

# ODE arguments
coeffs = [MU_EARTH, J2, 0] # Ignoring J3 for dynamics

# Process noise settings (SNC implementation)
sigma_a = 1e-8 # km/s^2
Q_psd = sigma_a**2 * np.eye(3)

# Set LKF options
# We now pack all Process Noise settings here for calculate_q_discrete
options = {
    'coeffs': coeffs,
    'abs_tol': 1e-10,
    'rel_tol': 1e-10,
    
    # --- New Process Noise Settings ---
    'method': 'SNC',          # Chosen method (SNC or DMC)
    'frame_type': 'RIC',      # Frame to apply noise in (RIC or ECI)
    'Q_cont': Q_psd,          # Continuous PSD matrix
    'threshold': 10.0,       # Max dt to prevent instability (example value)
    'B': None                 # Not needed for SNC
}

lkf_filter = LKF(n_states=6)

# Run LKF (Removed explicit Q argument, passing options containing Q_cont)
results = lkf_filter.run(obs, X_0, x_0, P0, Rk, options)

# Run post-processing
post_options = {
    'truth_traj_file': r'data\problem_2a_traj.csv',
    'save_to_timestamped_folder': True,
    'data_mask_idx': 0,
    'plot_state_errors': True,
    'plot_state_deviation': True,
    'plot_postfit_residuals': True,
    'plot_prefit_residuals': True,
    'plot_residual_comparison': True,
    'plot_covariance_trace': True,
    'plot_filter_consistency': True,
    'plot_covariance_ellipsoid': True,
    'plot_nis_metric': True
}

post_process(results, obs, post_options)

import os, sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d

# ============================================================
# Imports & Constants
# ============================================================
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from utils.orbital_element_conversions.oe_conversions import orbital_elements_to_inertial
from resources.constants import MU_EARTH, J2, J3, R_EARTH
from utils.filters.ekf_class import EKF

# ============================================================
# Configuration & Data Loading
# ============================================================

# Output directory for plots
output_dir = 'HW_3/plots'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# 1. Define Sweep Range
sigmas_to_test = np.logspace(-15, -2, num=20) / 1000 # Convert from m/s^2 to km/s^2

# 2. File Paths
meas_file = r'data/measurements_2a_noisy.csv'
truth_file = r'data/problem_2a_traj.csv'

# 3. Load & Clean Data
obs = pd.read_csv(meas_file)
obs.columns = obs.columns.str.strip() 

# Load Truth
truth_df = pd.read_csv(truth_file, 
                       delim_whitespace=True, 
                       header=None, 
                       names=['Time(s)', 'x', 'y', 'z', 'vx', 'vy', 'vz'])

# 4. Prepare Truth Interpolator
truth_interp = interp1d(truth_df['Time(s)'], 
                        truth_df[['x', 'y', 'z', 'vx', 'vy', 'vz']].values, 
                        axis=0, kind='cubic', fill_value="extrapolate") 

# ============================================================
# Initial Setup (Constant for all runs)
# ============================================================
# Initial Deviation
x_0_dev = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3])

# Initial Covariance & Noise
P0 = np.diag([1, 1, 1, 1e-3, 1e-3, 1e-3])**2
Rk = np.diag([1e-6, 1e-12])

# Reference Trajectory (Initial Guess)
r0, v0 = orbital_elements_to_inertial(10000, 0.001, 40, 80, 40, 0, units='deg')
Phi0 = np.eye(6).flatten()
X_0 = np.concatenate([r0 + x_0_dev[:3], v0 + x_0_dev[3:], Phi0])

# Base Filter Options (Q will be injected in loop)
coeffs = np.array([MU_EARTH, J2, 0])
ekf_options = {
    'coeffs': coeffs,
    'abs_tol': 1e-10,
    'rel_tol': 1e-10,
    'bootstrap_steps': 50, 
    
    # Process Noise Config
    'method': 'SNC',      # Use SNC method
    'frame_type': 'ECI',  # Frame to apply noise
    'threshold': 10.0,   # Max dt threshold
    'B': None             # Not used for SNC
}

# ============================================================
# Sweep Loop
# ============================================================
rms_pos_history = []
rms_vel_history = []
rms_res_range_history = []
rms_res_rr_history = []

print(f"Starting EKF Parameter Sweep over {len(sigmas_to_test)} values...")

# Instantiate EKF once (if stateless) or inside loop
ekf_filter = EKF(n_states=6)

for i, sigma_acc in enumerate(sigmas_to_test):
    print(f"--- Run {i+1}/{len(sigmas_to_test)}: Sigma = {sigma_acc*1000:.1e} m/s^2 ---")

    # 1. Update Process Noise (Q) for this iteration
    Q_psd = (sigma_acc**2) * np.eye(3)
    
    # Inject Q into options
    ekf_options['Q_cont'] = Q_psd

    # 2. Run EKF (New Signature: Q is inside options)
    results = ekf_filter.run(
        obs=obs,
        X_0=X_0,
        x_0=x_0_dev,
        P0=P0,
        Rk=Rk,
        options=ekf_options
    )

    # 3. Calculate Metrics
    # A. Get Truth at Filter Times
    # Filter typically outputs N-1 steps (skipping initial t0)
    # Adjust slicing based on your specific EKF implementation details
    filter_times = obs['Time(s)'].values[1:len(results.state_hist)+1]
    
    # Ensure lengths match exactly
    if len(filter_times) != len(results.state_hist):
        # Fallback slicing if filter didn't process all rows
        filter_times = obs['Time(s)'].values[1:1+len(results.state_hist)]
        
    truth_states = truth_interp(filter_times)

    # B. State Errors
    state_errors = results.state_hist - truth_states
    
    pos_err_3d = np.linalg.norm(state_errors[:, 0:3], axis=1)
    vel_err_3d = np.linalg.norm(state_errors[:, 3:6], axis=1)

    rms_pos = np.sqrt(np.mean(pos_err_3d**2))
    rms_vel = np.sqrt(np.mean(vel_err_3d**2))
    
    rms_pos_history.append(rms_pos)
    rms_vel_history.append(rms_vel)

    # C. Residual Errors
    res_range = results.postfit_residuals[:, 0]
    res_rr    = results.postfit_residuals[:, 1]
    
    rms_res_range = np.sqrt(np.mean(res_range**2))
    rms_res_rr    = np.sqrt(np.mean(res_rr**2))
    
    rms_res_range_history.append(rms_res_range)
    rms_res_rr_history.append(rms_res_rr)

print("\nSweep Complete. Generating Plots...")

# ============================================================
# Plotting
# ============================================================

# Plot (i): Post-fit Measurement Residual RMS vs Sigma
plt.figure(figsize=(10, 6))
plt.loglog(sigmas_to_test*1e3, rms_res_range_history, 'b-o', label='Range RMS (km)')
plt.loglog(sigmas_to_test*1e3, rms_res_rr_history, 'r-s', label='Range-Rate RMS (km/s)')
plt.xlabel(r'Process Noise Sigma $\sigma$ [$m/s^2$]')
plt.ylabel('Post-fit Residual RMS')
plt.title('i. EKF Measurement Residual RMS vs. Process Noise Sigma')
plt.grid(True, which="both", ls="-", alpha=0.5)
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'EKF_SNC_sweep_residuals.png'))

# Plot (ii): 3D State Error RMS vs Sigma
fig, ax1 = plt.subplots(figsize=(10, 6))

color = 'tab:blue'
ax1.set_xlabel(r'Process Noise Sigma $\sigma$ [$m/s^2$]')
ax1.set_ylabel('3D Position RMS [km]', color=color)
ax1.loglog(sigmas_to_test*1e3, rms_pos_history, 'o-', color=color, label='3D Position RMS')
ax1.tick_params(axis='y', labelcolor=color)
ax1.grid(True, which="both", ls="-", alpha=0.5)

ax2 = ax1.twinx()
color = 'tab:orange'
ax2.set_ylabel('3D Velocity RMS [km/s]', color=color)
ax2.loglog(sigmas_to_test*1e3, rms_vel_history, 's-', color=color, label='3D Velocity RMS')
ax2.tick_params(axis='y', labelcolor=color)

plt.title('ii. EKF 3D State Error RMS vs. Process Noise Sigma')
fig.tight_layout()
plt.savefig(os.path.join(output_dir, 'EKF_SNC_sweep_state_errors.png'))

import os, sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d

# ============================================================
# Imports & Constants
# ============================================================
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from utils.orbital_element_conversions.oe_conversions import orbital_elements_to_inertial
from resources.constants import MU_EARTH, J2, J3, R_EARTH
from utils.filters.lkf_class import LKF
from utils.plotting.post_process import post_process

# ============================================================
# Configuration
# ============================================================

# Output directory for plots
output_dir = 'HW_3/plots'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# 1. Define the Sweep Range (Sigma for Process Noise)
sigmas_to_test = np.logspace(-15, -2, num=20) / 1000 # Convert from m/s^2 to km/s^2

# 2. File Paths
meas_file = r'data/measurements_2a_noisy.csv'
truth_file = r'data/problem_2a_traj.csv'

# 3. Initial Setup
x_0 = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3])
P0 = np.diag([1, 1, 1e-3, 1, 1e-3, 1e-3])**2
Rk = np.diag([1e-6, 1e-12])

r0, v0 = orbital_elements_to_inertial(10000, 0.001, 40, 80, 40, 0, units='deg')
Phi0 = np.eye(6).flatten()
X_0_ref = np.concatenate([r0 + x_0[:3], v0 + x_0[3:], Phi0])

# ============================================================
# LOAD AND CLEAN DATA
# ============================================================
obs = pd.read_csv(meas_file)
obs.columns = obs.columns.str.strip()

# CORRECTED TRUTH FILE LOADING
truth_df = pd.read_csv(truth_file, 
                       delim_whitespace=True, 
                       header=None, 
                       names=['Time(s)', 'x', 'y', 'z', 'vx', 'vy', 'vz'])

# Prepare Truth Interpolator
truth_interp = interp1d(truth_df['Time(s)'], 
                        truth_df[['x', 'y', 'z', 'vx', 'vy', 'vz']].values, 
                        axis=0, kind='cubic', fill_value="extrapolate") # type: ignore

# ============================================================
# LKF BASE OPTIONS
# ============================================================
coeffs = [MU_EARTH, J2, 0] 

# Initialize the dictionary with static settings
# We will inject 'Q_cont' dynamically inside the loop
lkf_options = {
    'coeffs': coeffs,
    'abs_tol': 1e-10,
    'rel_tol': 1e-10,
    
    # --- New Process Noise Settings ---
    'method': 'SNC',          # Use State Noise Compensation
    'frame_type': 'ECI',      # Frame to apply noise (ECI or RIC)
    'threshold': 10.0,       # Max dt to prevent instability
    'B': None                 # Not needed for SNC
}

# ============================================================
# Storage for Sweep Metrics
# ============================================================
rms_pos_history = []
rms_vel_history = []
rms_res_range_history = []
rms_res_rr_history = []

# ============================================================
# Main Sweep Loop
# ============================================================
print(f"Starting SNC Parameter Sweep over {len(sigmas_to_test)} values...")

lkf_filter = LKF(n_states=6)

for i, sigma_acc in enumerate(sigmas_to_test):
    print(f"--- Run {i+1}/{len(sigmas_to_test)}: Sigma = {sigma_acc*1000:.1e} m/s^2 ---")

    # 1. Define Process Noise Spectral Density for this iteration
    Q_PSD = (sigma_acc**2) * np.eye(3) 
    
    # 2. Update options dictionary with current Q
    lkf_options['Q_cont'] = Q_PSD

    # 3. Run Filter (New Signature: Q is inside lkf_options)
    results = lkf_filter.run(obs, X_0_ref, x_0, P0, Rk, lkf_options)
    
    # --- CALCULATE METRICS FOR PLOTS ---
    
    # A. Get Truth State at the measurement times used in the filter
    # results.state_hist corresponds to k=1 to N (skipping initial state)
    # We slice obs time from index 0 to len(results) to match rows
    # (Assuming filter output aligns with input rows exactly)
    filter_times = obs['Time(s)'].values[:len(results.state_hist)]
    
    # Get Truth at these times
    truth_states = truth_interp(filter_times)
    
    # B. Compute State Errors (Estimated - Truth)
    state_errors = results.state_hist - truth_states
    
    pos_err_3d = np.linalg.norm(state_errors[:, 0:3], axis=1)
    vel_err_3d = np.linalg.norm(state_errors[:, 3:6], axis=1)
    
    # C. Compute RMS (Root Mean Square)
    rms_pos = np.sqrt(np.mean(pos_err_3d**2))
    rms_vel = np.sqrt(np.mean(vel_err_3d**2))
    
    rms_pos_history.append(rms_pos)
    rms_vel_history.append(rms_vel)

    # D. Compute Post-fit Residual RMS
    res_range = results.postfit_residuals[:, 0]
    res_rr    = results.postfit_residuals[:, 1]
    
    rms_res_range = np.sqrt(np.mean(res_range**2))
    rms_res_rr    = np.sqrt(np.mean(res_rr**2))
    
    rms_res_range_history.append(rms_res_range)
    rms_res_rr_history.append(rms_res_rr)

print("\nSweep Complete. Generating Summary Plots...")

# ============================================================
# PLOTTING
# ============================================================

# Plot (i): Post-fit Measurement Residual RMS vs Sigma
plt.figure(figsize=(10, 6))
plt.loglog(sigmas_to_test*1e3, rms_res_range_history, 'b-o', label='Range RMS (km)')
plt.loglog(sigmas_to_test*1e3, rms_res_rr_history, 'r-s', label='Range-Rate RMS (km/s)')
plt.xlabel(r'Process Noise Sigma $\sigma$ [$m/s^2$]')
plt.ylabel('Post-fit Residual RMS')
plt.title('i. Measurement Residual RMS vs. Process Noise Sigma')
plt.grid(True, which="both", ls="-", alpha=0.5)
plt.legend()
plt.savefig(os.path.join(output_dir, 'LKF_SNC_sweep_residuals.png'))
# plt.show()

# Plot (ii): 3D RMS Position and Velocity Errors vs Sigma
fig, ax1 = plt.subplots(figsize=(10, 6))

color = 'tab:blue'
ax1.set_xlabel(r'Process Noise Sigma $\sigma$ [$m/s^2$]')
ax1.set_ylabel('3D Position RMS [km]', color=color)
ax1.loglog(sigmas_to_test*1e3, rms_pos_history, 'o-', color=color, label='3D Position RMS')
ax1.tick_params(axis='y', labelcolor=color)
ax1.grid(True, which="both", ls="-", alpha=0.5)

ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis
color = 'tab:orange'
ax2.set_ylabel('3D Velocity RMS [km/s]', color=color)
ax2.loglog(sigmas_to_test*1e3, rms_vel_history, 's-', color=color, label='3D Velocity RMS')
ax2.tick_params(axis='y', labelcolor=color)

plt.title('ii. 3D State Error RMS vs. Process Noise Sigma')
fig.tight_layout()
plt.savefig(os.path.join(output_dir, 'LKF_SNC_sweep_state_errors.png'))
# plt.show()

import os, sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d

# ============================================================
# Imports & Constants
# ============================================================
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from utils.orbital_element_conversions.oe_conversions import orbital_elements_to_inertial
from resources.constants import MU_EARTH, J2, J3, R_EARTH
from utils.filters.lkf_class import LKF
from utils.plotting.post_process import post_process

# ============================================================
# Configuration
# ============================================================

# Output directory for plots
output_dir = 'HW_3/plots'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# 1. Define the Sweep Range (Sigma for Process Noise)
sigmas_to_test = np.logspace(-15, -2, num=20) / 1000 # Convert from m/s^2 to km/s^2

# 2. File Paths
meas_file = r'data/measurements_2a_noisy.csv'
truth_file = r'data/problem_2a_traj.csv'

# 3. Initial Setup
x_0 = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3])
P0 = np.diag([1, 1, 1e-3, 1, 1e-3, 1e-3])**2
Rk = np.diag([1e-6, 1e-12])

r0, v0 = orbital_elements_to_inertial(10000, 0.001, 40, 80, 40, 0, units='deg')
Phi0 = np.eye(6).flatten()
X_0_ref = np.concatenate([r0 + x_0[:3], v0 + x_0[3:], Phi0])

# ============================================================
# LOAD AND CLEAN DATA
# ============================================================
obs = pd.read_csv(meas_file)
obs.columns = obs.columns.str.strip()

# CORRECTED TRUTH FILE LOADING
truth_df = pd.read_csv(truth_file, 
                       delim_whitespace=True, 
                       header=None, 
                       names=['Time(s)', 'x', 'y', 'z', 'vx', 'vy', 'vz'])

# Prepare Truth Interpolator
truth_interp = interp1d(truth_df['Time(s)'], 
                        truth_df[['x', 'y', 'z', 'vx', 'vy', 'vz']].values, 
                        axis=0, kind='cubic', fill_value="extrapolate") # type: ignore

# ============================================================
# LKF BASE OPTIONS
# ============================================================
coeffs = [MU_EARTH, J2, 0] 

# Initialize the dictionary with static settings
# We will inject 'Q_cont' dynamically inside the loop
lkf_options = {
    'coeffs': coeffs,
    'abs_tol': 1e-10,
    'rel_tol': 1e-10,
    
    # --- New Process Noise Settings ---
    'method': 'SNC',          # Use State Noise Compensation
    'frame_type': 'ECI',      # Frame to apply noise (ECI or RIC)
    'threshold': 10.0,       # Max dt to prevent instability
    'B': None                 # Not needed for SNC
}

# ============================================================
# Storage for Sweep Metrics
# ============================================================
rms_pos_history = []
rms_vel_history = []
rms_res_range_history = []
rms_res_rr_history = []

# ============================================================
# Main Sweep Loop
# ============================================================
print(f"Starting SNC Parameter Sweep over {len(sigmas_to_test)} values...")

lkf_filter = LKF(n_states=6)

for i, sigma_acc in enumerate(sigmas_to_test):
    print(f"--- Run {i+1}/{len(sigmas_to_test)}: Sigma = {sigma_acc*1000:.1e} m/s^2 ---")

    # 1. Define Process Noise Spectral Density for this iteration
    Q_PSD = (sigma_acc**2) * np.eye(3) 
    
    # 2. Update options dictionary with current Q
    lkf_options['Q_cont'] = Q_PSD

    # 3. Run Filter (New Signature: Q is inside lkf_options)
    results = lkf_filter.run(obs, X_0_ref, x_0, P0, Rk, lkf_options)
    
    # --- CALCULATE METRICS FOR PLOTS ---
    
    # A. Get Truth State at the measurement times used in the filter
    # results.state_hist corresponds to k=1 to N (skipping initial state)
    # We slice obs time from index 0 to len(results) to match rows
    # (Assuming filter output aligns with input rows exactly)
    filter_times = obs['Time(s)'].values[:len(results.state_hist)]
    
    # Get Truth at these times
    truth_states = truth_interp(filter_times)
    
    # B. Compute State Errors (Estimated - Truth)
    state_errors = results.state_hist - truth_states
    
    pos_err_3d = np.linalg.norm(state_errors[:, 0:3], axis=1)
    vel_err_3d = np.linalg.norm(state_errors[:, 3:6], axis=1)
    
    # C. Compute RMS (Root Mean Square)
    rms_pos = np.sqrt(np.mean(pos_err_3d**2))
    rms_vel = np.sqrt(np.mean(vel_err_3d**2))
    
    rms_pos_history.append(rms_pos)
    rms_vel_history.append(rms_vel)

    # D. Compute Post-fit Residual RMS
    res_range = results.postfit_residuals[:, 0]
    res_rr    = results.postfit_residuals[:, 1]
    
    rms_res_range = np.sqrt(np.mean(res_range**2))
    rms_res_rr    = np.sqrt(np.mean(res_rr**2))
    
    rms_res_range_history.append(rms_res_range)
    rms_res_rr_history.append(rms_res_rr)

print("\nSweep Complete. Generating Summary Plots...")

# ============================================================
# PLOTTING
# ============================================================

# Plot (i): Post-fit Measurement Residual RMS vs Sigma
plt.figure(figsize=(10, 6))
plt.loglog(sigmas_to_test*1e3, rms_res_range_history, 'b-o', label='Range RMS (km)')
plt.loglog(sigmas_to_test*1e3, rms_res_rr_history, 'r-s', label='Range-Rate RMS (km/s)')
plt.xlabel(r'Process Noise Sigma $\sigma$ [$m/s^2$]')
plt.ylabel('Post-fit Residual RMS')
plt.title('i. Measurement Residual RMS vs. Process Noise Sigma')
plt.grid(True, which="both", ls="-", alpha=0.5)
plt.legend()
plt.savefig(os.path.join(output_dir, 'LKF_SNC_sweep_residuals.png'))
# plt.show()

# Plot (ii): 3D RMS Position and Velocity Errors vs Sigma
fig, ax1 = plt.subplots(figsize=(10, 6))

color = 'tab:blue'
ax1.set_xlabel(r'Process Noise Sigma $\sigma$ [$m/s^2$]')
ax1.set_ylabel('3D Position RMS [km]', color=color)
ax1.loglog(sigmas_to_test*1e3, rms_pos_history, 'o-', color=color, label='3D Position RMS')
ax1.tick_params(axis='y', labelcolor=color)
ax1.grid(True, which="both", ls="-", alpha=0.5)

ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis
color = 'tab:orange'
ax2.set_ylabel('3D Velocity RMS [km/s]', color=color)
ax2.loglog(sigmas_to_test*1e3, rms_vel_history, 's-', color=color, label='3D Velocity RMS')
ax2.tick_params(axis='y', labelcolor=color)

plt.title('ii. 3D State Error RMS vs. Process Noise Sigma')
fig.tight_layout()
plt.savefig(os.path.join(output_dir, 'LKF_SNC_sweep_state_errors.png'))
# plt.show()

import os, sys
import numpy as np
import pandas as pd
from scipy.interpolate import interp1d

# ============================================================
# Configuration & Imports
# ============================================================
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from utils.orbital_element_conversions.oe_conversions import orbital_elements_to_inertial
from resources.constants import MU_EARTH, J2
from utils.filters.lkf_class import LKF

meas_file = r'data/measurements_2a_noisy.csv'
truth_file = r'data/problem_2a_traj.csv'

# Constants
sigma_acc = 1e-8 # km/s^2
Q_PSD = (sigma_acc**2) * np.eye(3)

# Initial State
x_0 = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3])
P0 = np.diag([1, 1, 1, 1e-3, 1e-3, 1e-3])**2
Rk = np.diag([1e-6, 1e-12])
r0, v0 = orbital_elements_to_inertial(10000, 0.001, 40, 80, 40, 0, units='deg')
Phi0 = np.eye(6).flatten()
X_0_ref = np.concatenate([r0 + x_0[:3], v0 + x_0[3:], Phi0])

# ============================================================
# 1. ROBUST DATA LOADING
# ============================================================
# Load Measurements
obs = pd.read_csv(meas_file)
obs.columns = obs.columns.str.strip()

# Load Truth (Restored whitespace delimiter settings)
truth_df = pd.read_csv(truth_file, 
                       delim_whitespace=True, 
                       header=None, 
                       names=['Time(s)', 'x', 'y', 'z', 'vx', 'vy', 'vz'])

# Force columns to numeric to prevent string comparison errors
cols = ['x', 'y', 'z', 'vx', 'vy', 'vz']
for c in cols:
    truth_df[c] = pd.to_numeric(truth_df[c], errors='coerce')

# Create Interpolator
truth_interp = interp1d(truth_df['Time(s)'], 
                        truth_df[cols].values, 
                        axis=0, kind='cubic', fill_value="extrapolate")

# ============================================================
# 2. RUN CASES
# ============================================================
def run_case(frame_type):
    print(f"Running LKF with Process Noise in {frame_type} frame...")
    
    coeffs = [MU_EARTH, J2, 0]
    options = {
        'coeffs': coeffs,
        'abs_tol': 1e-10,
        'rel_tol': 1e-10,
        'method': 'SNC',
        'frame_type': frame_type,
        'Q_cont': Q_PSD,
        'threshold': 10.0,
        'B': None
    }
    
    lkf = LKF(n_states=6)
    results = lkf.run(obs, X_0_ref, x_0, P0, Rk, options)
    
    # Validation
    t_eval = obs['Time(s)'].values
    truth_states = truth_interp(t_eval)
    
    # Ensure shapes match
    n = min(len(results.state_hist), len(truth_states))
    est_states = np.array(results.state_hist)[:n]
    truth_states = truth_states[:n]
    
    state_errors = est_states - truth_states
    
    # Compute Float Metrics (Explicit Cast)
    pos_rms = float(np.sqrt(np.mean(np.linalg.norm(state_errors[:, :3], axis=1)**2)))
    vel_rms = float(np.sqrt(np.mean(np.linalg.norm(state_errors[:, 3:], axis=1)**2)))
    
    post_res = np.array(results.postfit_residuals)
    res_rng_rms = float(np.sqrt(np.mean(post_res[:, 0]**2)))
    res_rr_rms = float(np.sqrt(np.mean(post_res[:, 1]**2)))
    
    return {
        'Pos RMS (km)': pos_rms,
        'Vel RMS (km/s)': vel_rms,
        'Res Range (km)': res_rng_rms,
        'Res Rate (km/s)': res_rr_rms
    }

metrics_ric = run_case('RIC')
metrics_eci = run_case('ECI')

# ============================================================
# 3. COMPARISON & REPORTING
# ============================================================
# Create DataFrame fresh to avoid index duplicates from previous runs
df = pd.DataFrame([metrics_ric, metrics_eci], index=['RIC Frame', 'ECI Frame'])

# Calculate Delta
diff = df.loc['RIC Frame'] - df.loc['ECI Frame']
diff.name = 'Delta (RIC - ECI)'

# Append Delta row
df = pd.concat([df, diff.to_frame().T])

print("\n" + "="*60)
print(f"LKF SNC Comparison: Sigma = {sigma_acc} km/s^2")
print("="*60)
print(df.to_markdown(floatfmt=".6e"))
print("="*60)

print("\nInterpretation:")
# Explicit float casting for the comparison check
ric_val = float(df.loc['RIC Frame', 'Pos RMS (km)'])
eci_val = float(df.loc['ECI Frame', 'Pos RMS (km)'])

if ric_val < eci_val:
    print(f"--> RIC frame noise yielded lower Position Error.")
else:
    print(f"--> ECI frame noise yielded lower Position Error.")



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os, sys

# Adjust path to find local modules
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# --- Imports from your project ---
from utils.orbital_element_conversions.oe_conversions import orbital_elements_to_inertial
from resources.constants import MU_EARTH, J2, R_EARTH
from utils.filters.ekf_class_dmc import EKF 

# ============================================================
# CONFIGURATION
# ============================================================
output_dir = 'HW_3/plots_ekf_dmc_sweep'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

meas_file = r'data/measurements_2a_noisy.csv'
truth_file = r'data/problem_2a_traj.csv'

# 1. Define Sweep Range (Steady State Acceleration Sigma)
# Logspace from 1e-15 to 1e-2 m/s^2, converted to km/s^2
sigmas_test_m_s2 = np.logspace(-15, -2, num=15)
sigmas_test_km_s2 = sigmas_test_m_s2 / 1000.0 

# ============================================================
# 2. INITIALIZE STATE & ORBITAL PARAMETERS
# ============================================================

# Define Truth Initial State
r0_true, v0_true = orbital_elements_to_inertial(10000, 0.001, 40, 80, 40, 0, units='deg')
a0_true = np.zeros(3) 

# Calculate Orbit Period (P) for DMC tuning
r_mag = np.linalg.norm(r0_true)
v_mag = np.linalg.norm(v0_true)
energy = (v_mag**2 / 2) - (MU_EARTH / r_mag)
a_sma = -MU_EARTH / (2 * energy)
P_period = 2 * np.pi * np.sqrt(a_sma**3 / MU_EARTH)

print(f"Orbital Period P: {P_period:.2f} s")

# ============================================================
# 3. CONFIGURE DMC CONSTANTS
# ============================================================
tau = P_period / 30.0
beta = 1.0 / tau
print(f"DMC Time Constant tau: {tau:.2f} s")

# B Matrix (3x3 diagonal)
B_mat = np.eye(3) * beta

# Pack coefficients (Mu, J2, J3, B)
coeffs = (MU_EARTH, J2, 0, B_mat)

ekf_options = {
    'coeffs': coeffs,
    'abs_tol': 1e-10,
    'rel_tol': 1e-10,
    'dt_max': 60.0,
    'bootstrap_steps': 100
}

# ============================================================
# 4. SETUP INITIAL ESTIMATE & COVARIANCE
# ============================================================

# Initial Deviation (Error)
x_0_dev = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3, 0, 0, 0])

# Construct Initial Estimate (X_0)
r0_est = r0_true + x_0_dev[:3]
v0_est = v0_true + x_0_dev[3:6]
a0_est = a0_true + x_0_dev[6:9]

# EKF State: [rx, ry, rz, vx, vy, vz, ax, ay, az]
X_0_est = np.concatenate([r0_est, v0_est, a0_est])

# Initial Covariance (P0)
P0 = np.diag([
    1, 1, 1,              # Pos (km^2)
    1e-6, 1e-6, 1e-6,     # Vel (km^2/s^2)
    1e-9, 1e-9, 1e-9      # Accel (km^2/s^4)
])

# Measurement Noise
Rk = np.diag([1e-6, 1e-12])

# Initial Deviation estimate (0 for EKF)
x_hat_0 = np.zeros(9)

# ============================================================
# 5. LOAD & ALIGN DATA
# ============================================================
obs = pd.read_csv(meas_file)
obs.columns = obs.columns.str.strip()

# Load Truth
try:
    truth_df = pd.read_csv(truth_file, sep='\s+', header=None, 
                           names=['Time(s)', 'x', 'y', 'z', 'vx', 'vy', 'vz'])
except:
    truth_df = pd.read_csv(truth_file, delim_whitespace=True, header=None, 
                           names=['Time(s)', 'x', 'y', 'z', 'vx', 'vy', 'vz'])

# The EKF implementation typically processes measurements starting from index k=1 
# (skipping the initial condition at k=0).
# We filter the truth data to match exactly the timestamps the filter will output.
filter_meas_times = obs['Time(s)'].iloc[1:].values
truth_aligned = truth_df[truth_df['Time(s)'].isin(filter_meas_times)].copy()
truth_aligned = truth_aligned.sort_values('Time(s)')
truth_states_k = truth_aligned[['x', 'y', 'z', 'vx', 'vy', 'vz']].values

# ============================================================
# 6. SWEEP LOOP
# ============================================================
rms_pos_history = []
rms_vel_history = []
rms_res_range_history = []
rms_res_rr_history = []

print(f"\nStarting EKF DMC Sweep over {len(sigmas_test_km_s2)} values...")

for i, sigma_km in enumerate(sigmas_test_km_s2):
    sigma_m = sigmas_test_m_s2[i]
    print(f"--- Run {i+1}/{len(sigmas_test_km_s2)}: Sigma = {sigma_m:.1e} m/s^2 ---")

    # 1. Update Process Noise (Q_PSD)
    # Formula: q = 2 * sigma^2 * beta
    q_driving_noise = 2 * (sigma_km**2) * beta
    Q_PSD = q_driving_noise * np.eye(3)

    # 2. Run EKF
    ekf = EKF(n_states=9)
    results = ekf.run(obs, X_0_est, x_hat_0, P0, Rk, Q_PSD, ekf_options)

    # 3. Calculate Metrics
    # Ensure we only compare against aligned truth data
    # (Defensive check: slice to min length in case filter crashed early)
    n_pts = min(len(results.state_hist), len(truth_states_k))
    
    # Extract Position/Velocity (first 6 cols) from filter output
    # Note: results.state_hist might be (N, 9) or (N, 6) depending on your class fix.
    # We slice [:, :6] to be safe.
    est_states = results.state_hist[:n_pts, :6]
    truth_subset = truth_states_k[:n_pts, :]

    # State Errors
    pos_err = np.linalg.norm(est_states[:, 0:3] - truth_subset[:, 0:3], axis=1)
    vel_err = np.linalg.norm(est_states[:, 3:6] - truth_subset[:, 3:6], axis=1)

    rms_pos = np.sqrt(np.mean(pos_err**2))
    rms_vel = np.sqrt(np.mean(vel_err**2))
    
    rms_pos_history.append(rms_pos)
    rms_vel_history.append(rms_vel)

    # Residual Errors
    res_range = results.postfit_residuals[:n_pts, 0]
    res_rr    = results.postfit_residuals[:n_pts, 1]
    
    rms_res_range = np.sqrt(np.mean(res_range**2))
    rms_res_rr    = np.sqrt(np.mean(res_rr**2))
    
    rms_res_range_history.append(rms_res_range)
    rms_res_rr_history.append(rms_res_rr)

print("\nSweep Complete. Generating Plots...")

# ============================================================
# 7. PLOTTING
# ============================================================

# Plot (i): Post-fit Measurement Residual RMS vs Sigma
plt.figure(figsize=(10, 6))
# X-axis: m/s^2 (for readability), Y-axis: km
plt.loglog(sigmas_test_m_s2, rms_res_range_history, 'b-o', label='Range RMS (km)')
plt.loglog(sigmas_test_m_s2, rms_res_rr_history, 'r-s', label='Range-Rate RMS (km/s)')
plt.xlabel(r'Steady State Acceleration $\sigma$ [$m/s^2$]')
plt.ylabel('Post-fit Residual RMS')
plt.title(f'i. EKF (DMC) Residual RMS vs. Process Noise Sigma\n(Tau={tau:.1f}s)')
plt.grid(True, which="both", ls="-", alpha=0.5)
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'EKF_DMC_sweep_residuals.png'))

# Plot (ii): 3D State Error RMS vs Sigma
fig, ax1 = plt.subplots(figsize=(10, 6))

color = 'tab:blue'
ax1.set_xlabel(r'Steady State Acceleration $\sigma$ [$m/s^2$]')
ax1.set_ylabel('3D Position RMS [km]', color=color)
ax1.loglog(sigmas_test_m_s2, rms_pos_history, 'o-', color=color, label='3D Position RMS')
ax1.tick_params(axis='y', labelcolor=color)
ax1.grid(True, which="both", ls="-", alpha=0.5)

ax2 = ax1.twinx()
color = 'tab:orange'
ax2.set_ylabel('3D Velocity RMS [km/s]', color=color)
ax2.loglog(sigmas_test_m_s2, rms_vel_history, 's-', color=color, label='3D Velocity RMS')
ax2.tick_params(axis='y', labelcolor=color)

plt.title(f'ii. EKF (DMC) State Error RMS vs. Process Noise Sigma\n(Tau={tau:.1f}s)')
fig.tight_layout()
plt.savefig(os.path.join(output_dir, 'EKF_DMC_sweep_state_errors.png'))
plt.show()

print(f"Plots saved to {output_dir}")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os, sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# --- Imports from your project ---
from utils.orbital_element_conversions.oe_conversions import orbital_elements_to_inertial
from resources.constants import MU_EARTH, J2, R_EARTH
from utils.filters.lkf_class_dmc import LKF_DMC

# ============================================================
# CONFIGURATION
# ============================================================
output_dir = 'HW_3/plots_dmc'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

meas_file = r'data/measurements_2a_noisy.csv'
truth_file = r'data/problem_2a_traj.csv'

# DMC Sigma Sweep (Steady State Acceleration Sigma)
sigmas_to_test = np.logspace(-15, -2, num=15) / 1000 # Convert from m/s^2 to km/s^2 for consistency with state units

# ============================================================
# 1. INITIALIZE STATE & ORBITAL PARAMETERS
# ============================================================

# Define Truth Initial State (from Orbital Elements)
r0_true, v0_true = orbital_elements_to_inertial(10000, 0.001, 40, 80, 40, 0, units='deg')
a0_true = np.zeros(3) # Truth has no "DMC" acceleration bias

# Calculate Orbit Period (P) based on Truth
r_mag = np.linalg.norm(r0_true)
v_mag = np.linalg.norm(v0_true)
energy = (v_mag**2 / 2) - (MU_EARTH / r_mag)
a_sma = -MU_EARTH / (2 * energy)
P_period = 2 * np.pi * np.sqrt(a_sma**3 / MU_EARTH)

print(f"Orbital Period P: {P_period:.2f} s")

# ============================================================
# 2. CONFIGURE DMC CONSTANTS
# ============================================================
# Set Time Constant relative to Period
tau = P_period / 30.0
beta = 1.0 / tau
print(f"DMC Time Constant tau: {tau:.2f} s")

# Construct B Matrix (3x3 diagonal)
B_mat = np.eye(3) * beta

# Pack coefficients (Mu, J2, J3, B)
coeffs = (MU_EARTH, J2, 0, B_mat)

lkf_options = {
    'coeffs': coeffs,
    'abs_tol': 1e-10,
    'rel_tol': 1e-10
}

# ============================================================
# 3. SETUP REFERENCE TRAJECTORY & INITIAL COVARIANCE
# ============================================================

# Initial Deviation (Error) we apply to our estimate
x_0_dev = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3, 0, 0, 0])

# Construct the Initial Reference Trajectory (The "Best Estimate")
r0_ref = r0_true + x_0_dev[:3]
v0_ref = v0_true + x_0_dev[3:6]
a0_ref = a0_true + x_0_dev[6:9]
Phi0   = np.eye(9).flatten()

# This is the big vector passed to ODE45
X_0_ref = np.concatenate([r0_ref, v0_ref, a0_ref, Phi0])

# Initial Covariance (P0)
P0 = np.diag([
    1, 1, 1,              # Position Variance (1 km^2)
    1e-3, 1e-3, 1e-3,     # Velocity Variance
    1e-6, 1e-6, 1e-6      # Acceleration Variance (Small initial guess)
])**2

# Measurement Noise Matrix
Rk = np.diag([1e-3, 1e-6])

# The initial LKF deviation state (x_hat) must be ZERO.
x_hat_0 = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3, 0, 0, 0])

# ============================================================
# 4. LOAD DATA (MODIFIED: NO INTERPOLATION)
# ============================================================
obs = pd.read_csv(meas_file)
obs.columns = obs.columns.str.strip()

# Load Truth Data
try:
    truth_df = pd.read_csv(truth_file, sep='\s+', header=None, 
                           names=['Time(s)', 'x', 'y', 'z', 'vx', 'vy', 'vz'])
except:
    truth_df = pd.read_csv(truth_file, delim_whitespace=True, header=None, 
                           names=['Time(s)', 'x', 'y', 'z', 'vx', 'vy', 'vz'])

# --- KEY CHANGE: Filter Truth to match Measurement Times ---
# Instead of interpolating, we select the rows in truth_df where 
# 'Time(s)' matches the timestamps in our observation file.
meas_times = obs['Time(s)'].values

# Filter the truth dataframe
truth_aligned = truth_df[truth_df['Time(s)'].isin(meas_times)].copy()

# Sort to ensure time alignment (just in case)
truth_aligned = truth_aligned.sort_values('Time(s)')

# Extract the raw state vectors (x, y, z, vx, vy, vz) as a numpy array
# Shape: (N_measurements, 6)
truth_states_all = truth_aligned[['x', 'y', 'z', 'vx', 'vy', 'vz']].values

# Validation check to ensure data exists
if len(truth_states_all) == 0:
    raise ValueError("No matching timestamps found between Truth and Measurements! Check your data files.")

# ============================================================
# 5. SWEEP LOOP
# ============================================================
rms_pos_history = []
rms_vel_history = []
rms_res_range_history = []
rms_res_rr_history = []  

print(f"Starting DMC Sweep...")

for i, sigma in enumerate(sigmas_to_test):
    print(f"--- Run {i+1}/{len(sigmas_to_test)}: Sigma = {sigma:.1e} ---")

    # Calculate PSD (q) based on steady-state Variance (sigma^2)
    q_driving_noise = 2 * (sigma**2) * beta
    
    Q_PSD = q_driving_noise * np.eye(3)

    # Initialize and Run Filter
    lkf = LKF_DMC(n_states=9)
    results = lkf.run(obs, X_0_ref, x_hat_0, P0, Rk, Q_PSD, lkf_options)

    # --- METRICS ---    
    truth_states_k = truth_states_all[1:, :] 
    
    # Check shape alignment
    if len(results.state_hist) != len(truth_states_k):
        # Fallback if filter output length differs (e.g. if filter didn't skip t0)
        # This aligns the end of the truth array to the end of the results
        truth_states_k = truth_states_all[-len(results.state_hist):, :]

    # State Errors
    est_states_6 = results.state_hist[:, 0:6]
    pos_err = np.linalg.norm(est_states_6[:, 0:3] - truth_states_k[:, 0:3], axis=1)
    vel_err = np.linalg.norm(est_states_6[:, 3:6] - truth_states_k[:, 3:6], axis=1)
    
    rms_pos_history.append(np.sqrt(np.mean(pos_err**2)))
    rms_vel_history.append(np.sqrt(np.mean(vel_err**2)))
    
    # Residual Errors
    res_rng = results.postfit_residuals[:, 0]
    res_rr  = results.postfit_residuals[:, 1] 
    
    rms_res_range_history.append(np.sqrt(np.mean(res_rng**2)))
    rms_res_rr_history.append(np.sqrt(np.mean(res_rr**2)))

# ============================================================
# 6. PLOT
# ============================================================

# Plot 1: Position and Velocity RMS
plt.figure(figsize=(10,6))
plt.loglog(sigmas_to_test *1e3, rms_pos_history, 'b-o', label='Pos RMS (km)')
plt.loglog(sigmas_to_test *1e3, rms_vel_history, 'r-s', label='Vel RMS (km/s)')
plt.xlabel(r'Steady State Acceleration $\sigma$ [$m/s^2$]')
plt.ylabel('State RMS Error')
plt.title(f'LKF DMC State Accuracy Sweep (Tau={tau:.1f}s)')
plt.grid(True, which="both", ls="-", alpha=0.5)
plt.legend()
plt.savefig(os.path.join(output_dir, 'LKF_DMC_sweep_state_errors.png'))
plt.show()

# Plot 2: Measurement Residual RMS
plt.figure(figsize=(10,6))
plt.loglog(sigmas_to_test *1e3, rms_res_range_history, 'b-o', label='Range RMS (km)')
plt.loglog(sigmas_to_test *1e3, rms_res_rr_history, 'r-s', label='Range-Rate RMS (km/s)')
plt.xlabel(r'Steady State Acceleration $\sigma$ [$m/s^2$]')
plt.ylabel('Post-fit Residual RMS')
plt.title(f'LKF DMC Measurement Residual Sweep (Tau={tau:.1f}s)')
plt.grid(True, which="both", ls="-", alpha=0.5)
plt.legend()
plt.savefig(os.path.join(output_dir, 'LKF_DMC_sweep_residuals.png'))
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d
import os, sys

# Adjust path to find local modules
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# --- Imports from your project ---
from utils.orbital_element_conversions.oe_conversions import orbital_elements_to_inertial
from resources.constants import MU_EARTH, J2, R_EARTH
from utils.filters.ekf_class_dmc import EKF 
from utils.plotting.post_process import post_process

# ============================================================
# HELPER: J3 ACCELERATION MODEL
# ============================================================
def compute_J3_acceleration(r_vec):
    """
    Computes inertial acceleration due to J3 zonal harmonic.
    
    Args:
        r_vec (np.array): Position vector [x, y, z] (km)
        
    Returns:
        np.array: Acceleration vector [ax, ay, az] (km/s^2)
    """
    # Standard J3 Constant (unnormalized)
    J3 = -2.5327e-6 
    
    r_mag = np.linalg.norm(r_vec)
    x, y, z = r_vec
    
    # Pre-compute repeated terms
    Re_r = R_EARTH / r_mag
    z_r = z / r_mag
    
    # J3 Acceleration Vector Formula (Cartesian)
    # Derived from gradient of Potential U_3
    # a_vec = (mu * Re^3 * J3 / r^5) * [ coeff_r * r_vec + coeff_k * k_hat ]
    
    factor = (MU_EARTH * (R_EARTH**3) * J3) / (r_mag**5)
    
    coeff_r = (5/2) * (7 * (z_r**3) - 3 * z_r)
    coeff_k = (3/2) * (1 - 5 * (z_r**2))
    
    a_x = factor * (coeff_r * (x / r_mag))
    a_y = factor * (coeff_r * (y / r_mag))
    a_z = factor * (coeff_r * (z / r_mag) + coeff_k * (1.0/r_mag) * r_mag) # mult by r_mag to handle units, effectively just adding k component
    
    # Simplified:
    # The term is factor * [ coeff_r * (r_vec/r) + coeff_k * k_hat ]
    # Note: factor has /r^5. 
    
    # Re-calculation for clarity/safety:
    term_common = (MU_EARTH * R_EARTH**3 * J3) / (2 * r_mag**7)
    
    a_x = term_common * x * (15 * z_r**2 - 3) * (5 * z) # Wait, let's stick to the vector form:
    
    # Vector form: a = - mu/r^2 * (Re/r)^3 * J3 * [ ... ]
    # Using formula from Montenbruck & Gill (Satellite Orbits):
    const = MU_EARTH * (R_EARTH**3) * J3 / (2 * r_mag**7)
    
    tmp1 = 30 * z**2 - 6 * r_mag**2 # Term related to 5(z/r)^2
    tmp2 = 35 * z**3 - 15 * z * r_mag**2 # Term related to 7(z/r)^3
    
    # Note: Formulas vary by sign convention of J3. 
    # Usually J3 is negative (~ -2.5e-6).
    # Correct Cartesian expansion:
    ax = const * x * (15 * z**2 - 3 * r_mag**2)
    ay = const * y * (15 * z**2 - 3 * r_mag**2)
    az = const * (z * (15 * z**2 - 3 * r_mag**2) + (10 * z**3 - 6 * z * r_mag**2) * -1) # This is getting messy
    
    # Let's use the explicit textbook expansion:
    # ax = (mu/r^3) * (Re/r)^3 * J3 * (5/2 * (7(z/r)^3 - 3(z/r)) * x) ... No.
    
    # Clean Implementation:
    coef = (MU_EARTH / r_mag**2) * (R_EARTH / r_mag)**3 * J3
    
    # a_vec = coef * [ (5/2 * (7*u^3 - 3*u) * r_vec/r) + (3/2 * (1 - 5*u^2) * e_z) ]
    # where u = z/r
    
    u = z / r_mag
    
    term_r = (5.0/2.0) * (7*u**3 - 3*u)
    term_z = (3.0/2.0) * (1 - 5*u**2)
    
    accel = np.zeros(3)
    accel[0] = coef * (term_r * (x/r_mag))
    accel[1] = coef * (term_r * (y/r_mag))
    accel[2] = coef * (term_r * (z/r_mag) + term_z)
    
    return accel

# ============================================================
# CONFIGURATION
# ============================================================
output_dir = 'HW_3/plots_ekf_dmc'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

meas_file = r'data/measurements_2a_noisy.csv'
truth_file = r'data/problem_2a_traj.csv'

# ============================================================
# 1. INITIALIZE STATE
# ============================================================
r0_true, v0_true = orbital_elements_to_inertial(10000, 0.001, 40, 80, 40, 0, units='deg')
a0_true = np.zeros(3)

# Period Calc
r_mag = np.linalg.norm(r0_true)
v_mag = np.linalg.norm(v0_true)
energy = (v_mag**2 / 2) - (MU_EARTH / r_mag)
a_sma = -MU_EARTH / (2 * energy)
P_period = 2 * np.pi * np.sqrt(a_sma**3 / MU_EARTH)

# ============================================================
# 2. CONFIGURE DMC 
# ============================================================
tau = P_period / 3.0
beta = 1.0 / tau
B_mat = np.eye(3) * beta
coeffs = (MU_EARTH, J2, 0, B_mat) # Pass J3=0 to filter, it must estimate it

ekf_options = {
    'coeffs': coeffs,
    'abs_tol': 1e-10,
    'rel_tol': 1e-10,
    'dt_max': 60.0
}

# ============================================================
# 3. SETUP ESTIMATE & COVARIANCE
# ============================================================
x_0_dev = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3, 0, 0, 0])

r0_est = r0_true + x_0_dev[:3]
v0_est = v0_true + x_0_dev[3:6]
a0_est = a0_true + x_0_dev[6:9]
X_0_est = np.concatenate([r0_est, v0_est, a0_est])

P0 = np.diag([1, 1, 1, 1e-6, 1e-6, 1e-6, 1e-9, 1e-9, 1e-9])
Rk = np.diag([1e-6, 1e-12])
x_hat_0 = np.zeros(9)

# ============================================================
# 4. PROCESS NOISE (OPTIMAL SIGMA)
# ============================================================
sigma = 1e-8 # Optimal tuning from sweep
q_driving_noise = 2 * (sigma**2) * beta
Q_PSD = q_driving_noise * np.eye(3)

print(f"Running EKF with Sigma: {sigma}")

# ============================================================
# 5. LOAD & RUN
# ============================================================
obs = pd.read_csv(meas_file)
obs.columns = obs.columns.str.strip()

ekf = EKF(n_states=9)
results = ekf.run(obs, X_0_est, x_hat_0, P0, Rk, Q_PSD, ekf_options)

# Run standard post-processing first
post_options = {
    'truth_traj_file': truth_file,
    'save_to_timestamped_folder': False, # Save directly to output_dir
    'plot_state_errors': True,
    'plot_residual_comparison': True,
    'plot_nis_metric': True
}
# Note: Modified post_process call to support output_dir override if your utils support it
# Otherwise it saves to a timestamp folder. 

# ============================================================
# 6. J3 PERTURBATION vs. ESTIMATED W ANALYSIS (SCATTER)
# ============================================================
print("\nGenerating 'w' Term Analysis Scatter Plots...")

# --- 1. Load Truth Trajectory ---
try:
    truth_df = pd.read_csv(truth_file, sep='\s+', header=None, 
                           names=['Time(s)', 'x', 'y', 'z', 'vx', 'vy', 'vz'])
except:
    truth_df = pd.read_csv(truth_file, delim_whitespace=True, header=None, 
                           names=['Time(s)', 'x', 'y', 'z', 'vx', 'vy', 'vz'])

truth_interp = interp1d(truth_df['Time(s)'], truth_df[['x', 'y', 'z']].values, axis=0, kind='cubic')

# --- 2. Extract Data ---
meas_times = obs['Time(s)'].values[1:] 
w_estimated = np.array(results.accel_hist) 
cov_hist = np.array(results.P_hist)

# --- 3. Compute TRUE J3 Acceleration ---
w_true_J3 = []
for t in meas_times:
    r_t = truth_interp(t)
    a_j3 = compute_J3_acceleration(r_t) 
    w_true_J3.append(a_j3)
w_true_J3 = np.array(w_true_J3)

# --- 4. Define Mask ---
mask_idx = 500 

t_plot = meas_times[mask_idx:]
w_est_plot = w_estimated[mask_idx:]
w_true_plot = w_true_J3[mask_idx:]
w_error = w_est_plot - w_true_plot
w_sigmas = np.sqrt(np.diagonal(cov_hist[:, 6:9, 6:9], axis1=1, axis2=2))[mask_idx:]

# --- PLOT 1: Estimated w vs True J3 (Scatter) ---
fig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)
coords = ['x', 'y', 'z']

for i in range(3):
    # Plot True J3 Perturbation as black scatter
    axes[i].scatter(t_plot, w_true_plot[:, i] * 1e6, color='black', s=2, label='True $J_3$ Perturbation', alpha=0.6)
    
    # Plot Filter Estimated 'w' as red scatter
    axes[i].scatter(t_plot, w_est_plot[:, i] * 1e6, color='blue', s=2, label='Estimated w (DMC)', alpha=0.6)
    
    axes[i].set_ylabel(f'Accel {coords[i]} [mm/$s^2$]') 
    axes[i].grid(True, alpha=0.3)
    
    if i == 0:
        axes[i].legend(loc='upper right', markerscale=5)
        axes[i].set_title(f"DMC Estimated 'w' vs Actual $J_3$ Perturbation (Scatter)")

axes[2].set_xlabel('Time [s]')
plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'DMC_w_vs_J3_scatter.png'))
plt.show()

# --- PLOT 2: 'w' Estimation Error (Scatter) ---
fig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)

for i in range(3):
    # Error = Estimated w - True J3 as blue scatter
    axes[i].scatter(t_plot, w_error[:, i] * 1e6, color='blue', s=2, label='Error (w - J3)', alpha=0.6)
    
    # 3-Sigma Bounds (Kept as fill_between for visual clarity of the envelope)
    axes[i].fill_between(t_plot, 
                         1 * w_sigmas[:, i] * 1e6, 
                         -1 * w_sigmas[:, i] * 1e6, 
                         color='red', alpha=0.15, label='1$\sigma$ Bound')
    
    axes[i].set_ylabel(f'Error {coords[i]} [mm/$s^2$]')
    axes[i].grid(True, alpha=0.3)
    
    # Stats
    rms = np.sqrt(np.mean(w_error[:, i]**2))
    axes[i].text(0.02, 0.85, f"RMS: {rms*1e6:.4f} mm/s^2", transform=axes[i].transAxes, 
                 bbox=dict(facecolor='white', alpha=0.5))

axes[0].set_title(f"Error in Estimating $J_3$ Perturbation (w) (Scatter)")
axes[0].legend(loc='upper right', markerscale=5)
axes[2].set_xlabel('Time [s]')

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'DMC_w_Error_scatter.png'))
plt.show()

print(f"Analysis complete. Scatter plots saved to {output_dir}")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d
from scipy.integrate import solve_ivp
from scipy.linalg import expm
from dataclasses import dataclass
from typing import Any
import os, sys

# Adjust path to find local modules
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# --- Imports from your project ---
from utils.orbital_element_conversions.oe_conversions import orbital_elements_to_inertial
from resources.constants import MU_EARTH, J2, R_EARTH
from utils.plotting.post_process import post_process
from utils.ground_station_utils.gs_latlon import get_gs_eci_state
from utils.ground_station_utils.gs_meas_model_H import compute_H_matrix, compute_rho_rhodot
from utils.zonal_harmonics.zonal_harmonics import zonal_sph_ode_dmc, get_zonal_jacobian_dmc
from resources.gs_locations_latlon import stations_ll

# ============================================================
# DATA STRUCTURES & HELPERS
# ============================================================
@dataclass
class LKFResults:
    dx_hist: Any
    P_hist: Any
    state_hist: Any
    innovations: Any
    postfit_residuals: Any
    nis_hist: Any
    accel_hist: Any 

    def __post_init__(self):
        self.dx_hist = np.array(self.dx_hist)
        self.P_hist = np.array(self.P_hist)
        self.state_hist = np.array(self.state_hist)
        self.innovations = np.array(self.innovations)
        self.postfit_residuals = np.array(self.postfit_residuals)
        self.nis_hist = np.array(self.nis_hist)
        if self.accel_hist is not None:
            self.accel_hist = np.array(self.accel_hist)

def compute_van_loan(A_mat, G_mat, Q_cont, dt):
    n = A_mat.shape[0]
    GQGt = G_mat @ Q_cont @ G_mat.T
    top = np.hstack((-A_mat, GQGt))
    bot = np.hstack((np.zeros((n, n)), A_mat.T))
    M_exp = expm(np.vstack((top, bot)) * dt)
    Phi_k = M_exp[n:, n:].T  
    Q_k = Phi_k @ M_exp[0:n, n:]
    return Phi_k, Q_k

def compute_J3_acceleration(r_vec):
    """Analytical J3 acceleration for truth comparison."""
    J3 = -2.5327e-6 
    r_mag = np.linalg.norm(r_vec)
    x, y, z = r_vec
    u = z / r_mag
    coef = (MU_EARTH / r_mag**2) * (R_EARTH / r_mag)**3 * J3
    term_r = (5.0/2.0) * (7*u**3 - 3*u)
    term_z = (3.0/2.0) * (1 - 5*u**2)
    return np.array([
        coef * (term_r * (x/r_mag)),
        coef * (term_r * (y/r_mag)),
        coef * (term_r * (z/r_mag) + term_z)
    ])

# ============================================================
# LKF DMC CLASS
# ============================================================
class LKF_DMC:
    def __init__(self, n_states: int = 9):
        self.n = n_states
        self.I = np.eye(n_states)

    def run(self, obs, X_0, x_0, P0, Rk, Q_PSD, options) -> LKFResults:
        coeffs = options['coeffs']
        dt_max = options.get('dt_max', 60.0) 
        G = np.zeros((9, 3))
        G[6:9, :] = np.eye(3)
        time_eval = obs['Time(s)'].values

        sol_ref = solve_ivp(zonal_sph_ode_dmc, (0, time_eval[-1]), X_0, 
                            dense_output=True, args=(coeffs,), 
                            rtol=options['rel_tol'], atol=options['abs_tol'])
        ref_traj = sol_ref.sol
        x, P = x_0.copy(), P0.copy()
        _x, _P, _state, _prefit_res, _postfit_res, _nis, _w_terms = [], [], [], [], [], [], []

        for k in range(1, len(time_eval)):
            t_prev, t_curr = time_eval[k-1], time_eval[k]
            t_internal = t_prev
            
            while t_internal < t_curr:
                h = min(dt_max, t_curr - t_internal)
                ref_s = ref_traj(t_internal)[0:9]
                A = get_zonal_jacobian_dmc(ref_s[0:3], ref_s[3:6], coeffs)
                Phi_s, Q_s = compute_van_loan(A, G, Q_PSD, h)
                x, P = Phi_s @ x, Phi_s @ P @ Phi_s.T + Q_s
                t_internal += h
            
            ref_k = ref_traj(t_curr)[0:9]
            meas_row = obs.iloc[k]
            station_idx = int(meas_row['Station_ID']) - 1
            Rs, Vs = get_gs_eci_state(stations_ll[station_idx][0], stations_ll[station_idx][1], 
                                      t_curr, init_theta=np.deg2rad(122))
            
            H = np.hstack([compute_H_matrix(ref_k[0:3], ref_k[3:6], Rs, Vs), np.zeros((2, 3))])
            y_pred = compute_rho_rhodot(ref_k[0:6], np.concatenate([Rs, Vs]))
            innovation = (np.array([meas_row['Range(km)'], meas_row['Range_Rate(km/s)']]) - y_pred) - H @ x

            S = H @ P @ H.T + Rk
            K = (np.linalg.solve(S, H @ P)).T
            x = x + K @ innovation
            IKH = self.I - K @ H
            P = IKH @ P @ IKH.T + K @ Rk @ K.T

            # Save total estimated acceleration (Ref + Deviation)
            _w_terms.append((ref_k[6:9] + x[6:9]).copy())
            _x.append(x.copy()); _P.append(P.copy()); _nis.append(innovation.T @ np.linalg.solve(S, innovation))
            _state.append((ref_k + x).copy()); _postfit_res.append(innovation - H @ (K @ innovation))

        return LKFResults(_x, _P, _state, [], _postfit_res, _nis, accel_hist=_w_terms)

# ============================================================
# MAIN EXECUTION
# ============================================================
output_dir = 'HW_3/plots_dmc'
if not os.path.exists(output_dir): os.makedirs(output_dir)

meas_file, truth_file = r'data/measurements_2a_noisy.csv', r'data/problem_2a_traj.csv'
r0_true, v0_true = orbital_elements_to_inertial(10000, 0.001, 40, 80, 40, 0, units='deg')

# Period and DMC Config
a_sma = -MU_EARTH / (2 * ((np.linalg.norm(v0_true)**2 / 2) - (MU_EARTH / np.linalg.norm(r0_true))))
P_period = 2 * np.pi * np.sqrt(a_sma**3 / MU_EARTH)
beta = 1.0 / (P_period / 30.0)

obs = pd.read_csv(meas_file)
obs.columns = obs.columns.str.strip()
truth_df = pd.read_csv(truth_file, delim_whitespace=True, header=None, names=['T', 'x', 'y', 'z', 'vx', 'vy', 'vz'])
truth_interp = interp1d(truth_df['T'], truth_df[['x', 'y', 'z']].values, axis=0, kind='cubic')

# Run LKF
x_0_dev = np.array([0.1, -0.03, 0.25, 0.3e-3, -0.5e-3, 0.2e-3, 0, 0, 0])
X_0_ref = np.concatenate([r0_true + x_0_dev[:3], v0_true + x_0_dev[3:6], [0,0,0], np.eye(9).flatten()])
lkf = LKF_DMC()
results = lkf.run(obs, X_0_ref, x_0_dev, np.diag([1,1,1,1e-6,1e-6,1e-6,1e-9,1e-9,1e-9]), 
                  np.diag([1e-6, 1e-12]), (2*(1e-8**2)*beta)*np.eye(3), 
                  {'coeffs': (MU_EARTH, J2, 0, np.eye(3)*beta), 'abs_tol': 1e-10, 'rel_tol': 1e-10})

# ============================================================
# ANALYSIS & SCATTER PLOTS
# ============================================================
mask_idx = 500
t_plot = obs['Time(s)'].values[1:][mask_idx:]
w_est = results.accel_hist[mask_idx:]
w_true = np.array([compute_J3_acceleration(truth_interp(t)) for t in t_plot])
w_err = (w_est - w_true) * 1e6
w_sig = np.sqrt(np.diagonal(results.P_hist[:, 6:9, 6:9], axis1=1, axis2=2))[mask_idx:] * 1e6

fig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)
for i, c in enumerate(['x', 'y', 'z']):
    axes[i].scatter(t_plot, w_true[:, i]*1e6, color='black', s=2, alpha=0.5, label='True $J_3$')
    axes[i].scatter(t_plot, w_est[:, i]*1e6, color='blue', s=2, alpha=0.5, label='LKF DMC')
    axes[i].set_ylabel(f'{c} [mm/$s^2$]')
    axes[i].grid(True, alpha=0.3)
axes[0].set_title("LKF Estimated Acceleration vs Actual $J_3$ (Scatter)")
axes[0].legend(loc='upper right', markerscale=5)
plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'LKF_DMC_accel_comparison.png'))
plt.show()

fig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)
for i, c in enumerate(['x', 'y', 'z']):
    axes[i].scatter(t_plot, w_err[:, i], color='blue', s=2, alpha=0.6)
    axes[i].fill_between(t_plot, w_sig[:, i], -w_sig[:, i], color='red', alpha=0.15, label='1$\sigma$')
    axes[i].set_ylabel(f'Err {c} [mm/$s^2$]')
    axes[i].grid(True, alpha=0.3)
axes[0].set_title("LKF DMC Estimation Error vs 1-Sigma Bounds")
plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'LKF_DMC_accel_error.png'))
plt.show()

import numpy as np
from dataclasses import dataclass
from typing import Any
from scipy.integrate import solve_ivp

# Local Imports
from utils.ground_station_utils.gs_latlon import get_gs_eci_state
from utils.ground_station_utils.gs_meas_model_H import compute_H_matrix, compute_rho_rhodot
from resources.gs_locations_latlon import stations_ll
from utils.misc.print_progress import print_progress
from utils.zonal_harmonics.zonal_harmonics import zonal_sph_ode_6x6, zonal_sph_ode_dmc
from utils.process_noise.compute_q_discrete import compute_q_discrete

@dataclass
class LKFResults:
    dx_hist: Any
    P_hist: Any
    state_hist: Any
    innovations: Any
    postfit_residuals: Any
    nis_hist: Any

    def __post_init__(self):
        self.dx_hist = np.array(self.dx_hist)
        self.P_hist = np.array(self.P_hist)
        self.state_hist = np.array(self.state_hist)
        self.innovations = np.array(self.innovations)
        self.postfit_residuals = np.array(self.postfit_residuals)
        self.nis_hist = np.array(self.nis_hist)

# ============================================================
# Linearized Kalman Filter
# ============================================================
class LKF:
    def __init__(self, n_states: int = 6):
        self.n = n_states
        self.I = np.eye(n_states)

    def run(self, obs, X_0, x_0, P0, Rk, options) -> LKFResults:
        print(f"Initializing Fast LKF (One-Shot Integration) with n={self.n}...")
        
        # 1. Setup
        coeffs = options['coeffs']
        abs_tol = options['abs_tol']
        rel_tol = options['rel_tol']
        
        if options.get('method') == 'DMC':
            ode_func = zonal_sph_ode_dmc
        else:
            ode_func = zonal_sph_ode_6x6

        # Initialize State Variables
        X_ref_init = X_0[0:self.n]
        x_dev = x_0.copy()
        P = P0.copy()
        
        # Extract all time points
        times = obs['Time(s)'].values
        t_start = times[0]
        t_end = times[-1]
        
        # 2. ONE-SHOT INTEGRATION
        # ------------------------------------------------------------------
        # We integrate the Reference State and the Cumulative STM (Phi) 
        # from start to finish in one call.
        
        print(f"   Propagating reference trajectory for {len(times)} steps...")
        
        # Initial State: [Reference, Identity_STM]
        state_integ_0 = np.concatenate([X_ref_init, np.eye(self.n).flatten()])
        
        sol = solve_ivp(
            ode_func, 
            (t_start, t_end), 
            state_integ_0, 
            t_eval=times,  # Force output exactly at measurement times
            args=(coeffs,), 
            rtol=abs_tol, 
            atol=rel_tol
        )
        
        # Unpack results: Shape is (n_states, n_times)
        X_ref_all = sol.y[0:self.n, :]
        Phi_all_flat = sol.y[self.n:, :]
        
        # 3. FILTER LOOP
        # ------------------------------------------------------------------
        _x, _P, _state, _prefit_res, _postfit_res, _nis = [], [], [], [], [], []
        
        # The integration includes the start time at index 0.
        # We iterate starting from k=1 (the second point).
        
        for k in range(1, len(times)):
            # Print progress less frequently to save I/O time
            if k % 100 == 0: print_progress(k, len(times))

            t_curr = times[k]
            t_prev = times[k-1]
            dt = t_curr - t_prev
            meas_row = obs.iloc[k]

            # --- A. Extract Pre-Computed State & STM ---
            X_ref_curr = X_ref_all[:, k]
            
            # Get Cumulative STMs: Phi(t_k, t0) and Phi(t_{k-1}, t0)
            Phi_cum_curr = Phi_all_flat[:, k].reshape(self.n, self.n)
            Phi_cum_prev = Phi_all_flat[:, k-1].reshape(self.n, self.n)
            
            # Compute Step STM: Phi(t_k, t_{k-1}) = Phi(t_k, t0) @ inv(Phi(t_{k-1}, t0))
            # This is the "transition from previous step to now"
            Phi_step = Phi_cum_curr @ np.linalg.inv(Phi_cum_prev)

            # --- B. Time Update (Prediction) ---
            # Propagate deviation: x_dev_k = Phi_step * x_dev_{k-1}
            x_dev_pred = Phi_step @ x_dev
            
            # Process Noise
            Q_k = compute_q_discrete(dt, X_ref_curr, options)
            
            # Propagate Covariance
            P_pred = Phi_step @ P @ Phi_step.T + Q_k

            # --- C. Measurement Update ---
            station_idx = int(meas_row['Station_ID']) - 1
            Rs, Vs = get_gs_eci_state(
                stations_ll[station_idx][0], 
                stations_ll[station_idx][1], 
                t_curr
            )
            
            # Measurement Models
            y_pred_ref = compute_rho_rhodot(X_ref_curr[0:6], np.concatenate([Rs, Vs]))
            y_obs = np.array([meas_row['Range(km)'], meas_row['Range_Rate(km/s)']])
            
            # Prefit Residual
            prefit_res = y_obs - y_pred_ref
            
            # H Matrix
            H_6 = compute_H_matrix(X_ref_curr[0:3], X_ref_curr[3:6], Rs, Vs)
            if self.n > 6:
                H = np.hstack([H_6, np.zeros((2, self.n - 6))])
            else:
                H = H_6
                
            # Kalman Gain
            innovation = prefit_res - H @ x_dev_pred
            S = H @ P_pred @ H.T + Rk
            K = P_pred @ H.T @ np.linalg.inv(S)
            
            # State Update
            x_dev = x_dev_pred + K @ innovation
            
            # Covariance Update (Joseph Form)
            IKH = self.I - K @ H
            P = IKH @ P_pred @ IKH.T + K @ Rk @ K.T
            
            # --- D. Storage ---
            nis = innovation.T @ np.linalg.solve(S, innovation)
            postfit_res = prefit_res - H @ x_dev
            X_total_est = X_ref_curr + x_dev

            _x.append(x_dev.copy())
            _P.append(P.copy())
            _state.append(X_total_est.copy())
            _prefit_res.append(prefit_res.copy())
            _postfit_res.append(postfit_res.copy())
            _nis.append(nis.copy())

        # Final cumulative STM is simply the last extracted cumulative STM
        Phi_final = Phi_all_flat[:, -1].reshape(self.n, self.n)

        return LKFResults(_x, _P, _state, _prefit_res, _postfit_res, _nis)
    

    

    import numpy as np
from scipy.integrate import solve_ivp
from scipy.linalg import expm
from dataclasses import dataclass
from typing import Any

# --- LOCAL IMPORTS ---
from utils.ground_station_utils.gs_latlon import get_gs_eci_state
from utils.ground_station_utils.gs_meas_model_H import compute_H_matrix, compute_rho_rhodot
from utils.zonal_harmonics.zonal_harmonics import zonal_sph_ode_dmc, get_zonal_jacobian_dmc
from resources.gs_locations_latlon import stations_ll

@dataclass
class LKFResults:
    dx_hist: Any
    P_hist: Any
    state_hist: Any
    innovations: Any
    postfit_residuals: Any
    nis_hist: Any
    accel_hist: Any 

    def __post_init__(self):
        self.dx_hist = np.array(self.dx_hist)
        self.P_hist = np.array(self.P_hist)
        self.state_hist = np.array(self.state_hist)
        self.innovations = np.array(self.innovations)
        self.postfit_residuals = np.array(self.postfit_residuals)
        self.nis_hist = np.array(self.nis_hist)

        if self.accel_hist is not None:
            self.accel_hist = np.array(self.accel_hist)

# --- HELPER FUNCTIONS ---

def compute_van_loan(A_mat, G_mat, Q_cont, dt):
    """
    Computes both the Discrete Process Noise (Q_k) AND the 
    Discrete State Transition Matrix (Phi_k) for the step dt.
    """
    n = A_mat.shape[0]
    
    # Construct the Van Loan Matrix M
    # [ -A    G*Q*G.T ]
    # [  0     A.T    ]
    zeros_n = np.zeros((n, n))
    GQGt = G_mat @ Q_cont @ G_mat.T
    
    top = np.hstack((-A_mat, GQGt))
    bot = np.hstack((zeros_n, A_mat.T))
    M = np.vstack((top, bot)) * dt
    
    # Matrix Exponential
    M_exp = expm(M)
    
    # 1. Extract Phi_k (The Incremental STM)
    Phi_T_block = M_exp[n:, n:]
    Phi_k = Phi_T_block.T  
    
    # 2. Extract Q_k
    Phi_inv_Qk = M_exp[0:n, n:]
    Q_k = Phi_k @ Phi_inv_Qk
    
    return Phi_k, Q_k


# --- MAIN CLASS ---
class LKF_DMC:
    def __init__(self, n_states: int = 9):
        self.n = n_states
        self.I = np.eye(n_states)

    def run(self, obs, X_0, x_0, P0, Rk, Q_PSD, options) -> LKFResults:
        print("Initializing LKF with DMC...")
        
        coeffs = options['coeffs']
        abs_tol = options['abs_tol']
        rel_tol = options['rel_tol']
        
        # FIX: Define a maximum step size for propagation (e.g., 60 seconds)
        # This prevents linearization errors over large gaps
        dt_max = options.get('dt_max', 60.0) 
        
        # Mapping matrix G (9x3)
        G = np.zeros((9, 3))
        G[6:9, :] = np.eye(3)

        time_eval = obs['Time(s)'].values

        # 1. Integrate Reference Trajectory (Dense Output)
        # We perform one global integration but enable 'dense_output'
        # so we can query the state at any sub-step time.
        sol_ref = solve_ivp(
                zonal_sph_ode_dmc, 
                (0, time_eval[-1]), 
                X_0, 
                t_eval=None,      # Allow solver to choose its own steps for accuracy
                dense_output=True, # REQUIRED for sub-stepping interpolation
                args=(coeffs,),
                rtol=abs_tol, 
                atol=rel_tol
        )
        
        # Create a function to access reference state at any time t
        ref_traj = sol_ref.sol

        x = x_0.copy()
        P = P0.copy()
        
        _x, _P, _state, _prefit_res, _postfit_res, _nis, _w_terms = [], [], [], [], [], [], []

        # Iterate through measurement times
        for k in range(1, len(time_eval)):
            t_prev = time_eval[k-1]
            t_curr = time_eval[k]
            
            # --- SUB-STEPPING PROPAGATION ---
            # Instead of one giant jump, we loop from t_prev to t_curr
            # in small increments (dt_max).
            
            t_internal = t_prev
            
            while t_internal < t_curr:
                # Determine step size h (don't overshoot t_curr)
                h = min(dt_max, t_curr - t_internal)
                
                # 1. Get Reference State at start of sub-step
                ref_state_local = ref_traj(t_internal)[0:9]
                r_vec_local = ref_state_local[0:3]
                v_vec_local = ref_state_local[3:6]
                
                # 2. Compute Jacobian A(t) at this specific location
                A_mat = get_zonal_jacobian_dmc(r_vec_local, v_vec_local, coeffs)
                
                # 3. Compute Phi and Q for this small step h
                Phi_step, Q_step = compute_van_loan(A_mat, G, Q_PSD, h)
                
                # 4. Propagate Error State and Covariance
                x = Phi_step @ x
                P = Phi_step @ P @ Phi_step.T + Q_step
                
                # Advance internal time
                t_internal += h
            
            # --- MEASUREMENT UPDATE (At t_curr) ---
            
            # Get Reference State exactly at measurement time
            ref_state_k = ref_traj(t_curr)[0:9]
            r_vec = ref_state_k[0:3]
            v_vec = ref_state_k[3:6]
            
            meas_row = obs.iloc[k]
            station_idx = int(meas_row['Station_ID']) - 1
            Rs, Vs = get_gs_eci_state(
                stations_ll[station_idx][0], 
                stations_ll[station_idx][1], 
                t_curr, 
                init_theta=np.deg2rad(122)
            )
            
            # H Matrix
            H_spatial = compute_H_matrix(r_vec, v_vec, Rs, Vs)
            H = np.hstack([H_spatial, np.zeros((2, 3))])
            
            y_pred_ref = compute_rho_rhodot(ref_state_k[0:6], np.concatenate([Rs, Vs]))
            y_obs = np.array([meas_row['Range(km)'], meas_row['Range_Rate(km/s)']])
            
            prefit_res = y_obs - y_pred_ref
            innovation = prefit_res - H @ x

            S = H @ P @ H.T + Rk
            K = (np.linalg.solve(S, H @ P)).T
            
            x = x + K @ innovation
            
            # Joseph Form Update
            IKH = self.I - K @ H
            P = IKH @ P @ IKH.T + K @ Rk @ K.T

            postfit_res = prefit_res - H @ x
            nis = innovation.T @ np.linalg.solve(S, innovation)

            # Store w terms
            w_current = x[6:9].copy()  # Extract current w estimate
            _w_terms.append(w_current)

            _x.append(x.copy())
            _P.append(P.copy())
            _state.append((ref_state_k + x).copy())
            _prefit_res.append(prefit_res.copy())
            _postfit_res.append(postfit_res.copy())
            _nis.append(nis.copy())

        return LKFResults(_x, _P, _state, _prefit_res, _postfit_res, _nis, accel_hist=_w_terms)

import numpy as np
from scipy.integrate import solve_ivp
from dataclasses import dataclass
from typing import Any

# Local Imports
from utils.ground_station_utils.gs_latlon import get_gs_eci_state
from utils.ground_station_utils.gs_meas_model_H import compute_H_matrix, compute_rho_rhodot
from resources.gs_locations_latlon import stations_ll
from utils.misc.print_progress import print_progress
from utils.zonal_harmonics.zonal_harmonics import zonal_sph_ode_6x6
from utils.process_noise.compute_q_discrete import compute_q_discrete 

@dataclass
class FilterResults:
    dx_hist: Any             
    P_hist: Any              
    state_hist: Any          
    innovations: Any         
    postfit_residuals: Any   
    nis_hist: Any 

    def __post_init__(self):
        self.dx_hist = np.array(self.dx_hist)
        self.P_hist = np.array(self.P_hist)
        self.state_hist = np.array(self.state_hist)
        self.innovations = np.array(self.innovations)
        self.postfit_residuals = np.array(self.postfit_residuals)
        self.nis_hist = np.array(self.nis_hist)

class EKF:
    def __init__(self, n_states: int = 6):
        self.n = n_states
        self.I = np.eye(n_states)

    def run(self, obs, X_0, x_0, P0, Rk, options):

        # Print filter start message
        print(f"Initializing EKF with n_states={self.n}...")
        
        # --- Initialization ---
        coeffs = options['coeffs']
        bootstrap_steps = options.get('bootstrap_steps', 0)
        abs_tol = options['abs_tol']
        rel_tol = options['rel_tol']
        
        # ODE Function: Default to 6x6 if not provided, but allow override for DMC (9x9)
        ode_func = options.get('ode_func', zonal_sph_ode_6x6)

        # --- COEFFICIENT SAFETY CHECK ---
        # If using the default 6x6 ODE but coeffs has 4 elements (mu, J2, J3, B),
        # slice it to prevent "too many values to unpack" error.
        if ode_func == zonal_sph_ode_6x6 and len(coeffs) > 3:
            coeffs_for_ode = coeffs[:3]
        else:
            coeffs_for_ode = coeffs

        # Initialize State: Generic slicing to support 6 (SNC) or 9 (DMC) states
        # X_curr is the full state vector (e.g., 9x1 for DMC)
        X_curr = X_0[0:self.n].copy()
        
        # Deviation Estimate (x_hat)
        x_dev = x_0.copy()
        
        P = P0.copy()
        
        _P, _state, _x = [], [], []
        _prefit_res, _postfit_res = [], []
        _nis_hist = []
        
        # Initialize time
        t_prev = obs.iloc[0]['Time(s)'] 

        # Loop starts at 1, propagating from t_prev (k-1) to t_curr (k)
        for k in range(1, len(obs)):
            meas_row = obs.iloc[k]
            t_curr = meas_row['Time(s)']
            dt = t_curr - t_prev

            # Print progress
            print_progress(k, len(obs))

            # -------------------------------------------------------
            # 1. PROPAGATION (Step-by-Step)
            # -------------------------------------------------------
            # Initial condition: Current Ref State (n) + Identity STM (n*n)
            # We reset STM to Identity at every step to ensure numerical stability.
            state_integ_0 = np.concatenate([X_curr, np.eye(self.n).flatten()])
            
            sol_step = solve_ivp(
                ode_func, 
                (t_prev, t_curr), 
                state_integ_0,
                args=(coeffs_for_ode,),
                rtol=rel_tol, atol=abs_tol
            )
            
            # Extract propagated Reference (first n) and Step-STM (last n*n)
            X_ref_pred = sol_step.y[0:self.n, -1]
            Phi_step = sol_step.y[self.n:, -1].reshape(self.n, self.n)
            
            # Propagate Deviation: dx_k = Phi * dx_k-1
            x_dev_pred = Phi_step @ x_dev

            # --- PROCESS NOISE STEP ---
            # Use the new helper function to compute Q_k
            # It handles the rotation from RIC to ECI using position/velocity from X_ref_pred
            Q_k = compute_q_discrete(dt, X_ref_pred, options)
            
            # Propagate Covariance: P = Phi * P * Phi' + Q
            P_pred = Phi_step @ P @ Phi_step.T + Q_k
            
            # -------------------------------------------------------
            # 2. MEASUREMENT UPDATE
            # -------------------------------------------------------
            station_idx = int(meas_row['Station_ID']) - 1
            lat, lon = stations_ll[station_idx]
            Rs, Vs = get_gs_eci_state(lat, lon, t_curr, init_theta=np.deg2rad(122))
            
            # Predicted Observation (based on Reference)
            # compute_rho_rhodot expects 6-element state [r, v]
            y_pred_ref = compute_rho_rhodot(X_ref_pred[0:6], np.concatenate([Rs, Vs]))
            y_obs = np.array([meas_row['Range(km)'], meas_row['Range_Rate(km/s)']])
            
            # Residual (Observation - Reference)
            prefit_res = y_obs - y_pred_ref
            
            # H Matrix evaluated at Reference
            # compute_H_matrix returns 2x6. If n_states=9, we pad with zeros.
            H_6 = compute_H_matrix(X_ref_pred[0:3], X_ref_pred[3:6], Rs, Vs)
            
            if self.n > 6:
                # Pad H for extra states (e.g. DMC acceleration parameters)
                H = np.hstack([H_6, np.zeros((2, self.n - 6))])
            else:
                H = H_6
            
            # Innovation: dy - H * deviation_prediction
            innovation = prefit_res - H @ x_dev_pred 

            S = H @ P_pred @ H.T + Rk
            K = P_pred @ H.T @ np.linalg.inv(S)

            # NIS Calculation
            nis = innovation.T @ np.linalg.solve(S, innovation)
            
            # Update Deviation
            x_dev = x_dev_pred + K @ innovation
            x_dev_log = x_dev.copy()

            # Update Covariance (Joseph form)
            IKH = self.I - K @ H
            P = IKH @ P_pred @ IKH.T + K @ Rk @ K.T
            
            # -------------------------------------------------------
            # 3. RECTIFICATION (The Switch)
            # -------------------------------------------------------
            if k < bootstrap_steps:
                # === LKF Mode ===
                # Reference trajectory evolves naturally (X_curr = X_ref_pred)
                # Deviation grows large.
                X_curr = X_ref_pred
                
                # Best Estimate = Ref + Dev
                X_best_est = X_curr + x_dev
                
            else:
                # === EKF Mode ===
                # Absorb deviation into the reference at every step
                X_curr = X_ref_pred + x_dev
                
                # Reset deviation to zero
                x_dev = np.zeros(self.n)
                
                X_best_est = X_curr

            # -------------------------------------------------------
            # 4. LOGGING
            # -------------------------------------------------------
            postfit_res = prefit_res - H @ x_dev_log

            _x.append(x_dev_log.copy())
            _state.append(X_best_est.copy())
            _P.append(P.copy())
            _prefit_res.append(prefit_res.copy())
            _postfit_res.append(postfit_res.copy())
            _nis_hist.append(nis)
            
            t_prev = t_curr

        return FilterResults(_x, _P, _state, _prefit_res, _postfit_res, _nis_hist)


import numpy as np
from scipy.integrate import solve_ivp
from scipy.linalg import expm
from dataclasses import dataclass
from typing import Any, Optional

# Local Imports
from utils.ground_station_utils.gs_latlon import get_gs_eci_state
from utils.ground_station_utils.gs_meas_model_H import compute_H_matrix, compute_rho_rhodot
from resources.gs_locations_latlon import stations_ll
from utils.misc.print_progress import print_progress
from resources.constants import R_EARTH 

@dataclass
class FilterResults:
    dx_hist: Any             
    P_hist: Any              
    state_hist: Any          
    innovations: Any         
    postfit_residuals: Any   
    nis_hist: Any
    accel_hist: Optional[Any] = None

    def __post_init__(self):
        self.dx_hist = np.array(self.dx_hist)
        self.P_hist = np.array(self.P_hist)
        self.state_hist = np.array(self.state_hist)
        self.innovations = np.array(self.innovations)
        self.postfit_residuals = np.array(self.postfit_residuals)
        self.nis_hist = np.array(self.nis_hist)
        
        if self.accel_hist is not None:
            self.accel_hist = np.array(self.accel_hist)

# --- HELPER FUNCTIONS ---

def compute_van_loan(A_mat, G_mat, Q_cont, dt):
    """Computes Discrete Q_k and STM Phi_k via Van Loan."""
    n = A_mat.shape[0]
    zeros_n = np.zeros((n, n))
    GQGt = G_mat @ Q_cont @ G_mat.T
    
    top = np.hstack((-A_mat, GQGt))
    bot = np.hstack((zeros_n, A_mat.T))
    M = np.vstack((top, bot)) * dt
    
    # Pad computation for stability
    M_exp = expm(M)
    
    Phi_T_block = M_exp[n:, n:]
    Phi_k = Phi_T_block.T  
    
    Phi_inv_Qk = M_exp[0:n, n:]
    Q_k = Phi_k @ Phi_inv_Qk
    
    return Phi_k, Q_k

def dmc_ode_wrapper(t, y, coeffs):
    """
    Computes derivative for EKF-DMC.
    Handles 9-element (State) or 90-element (State + STM) inputs.
    Expects coeffs = (mu, J2, unused, B_mat)
    """
    r = y[0:3]
    v = y[3:6]
    a = y[6:9] 
    
    mu, J2, _, B_mat = coeffs 

    norm_r = np.linalg.norm(r)
    r2 = norm_r**2
    
    # Acceleration due to Gravity
    a_grav = -(mu / norm_r**3) * r
    
    # Acceleration due to J2
    z2 = r[2]**2
    factor_J2 = 1.5 * J2 * mu * (R_EARTH**2 / r2**2)
    tx = (r[0] / norm_r) * (5 * z2 / r2 - 1)
    ty = (r[1] / norm_r) * (5 * z2 / r2 - 1)
    tz = (r[2] / norm_r) * (5 * z2 / r2 - 3)
    a_J2 = factor_J2 * np.array([tx, ty, tz])

    # State Derivatives
    dr = v
    dv = a_grav + a_J2 + a 
    da = -B_mat @ a         

    dy_state = np.concatenate([dr, dv, da])

    # Handle STM Propagation if needed
    if len(y) == 90:
        Phi = y[9:].reshape((9, 9))
        
        A = np.zeros((9, 9))
        A[0:3, 3:6] = np.eye(3) 
        A[3:6, 6:9] = np.eye(3) 
        
        R3 = norm_r**3
        R5 = norm_r**5
        G = (3 * mu / R5) * np.outer(r, r) - (mu / R3) * np.eye(3)
        A[3:6, 0:3] = G 
        A[6:9, 6:9] = -B_mat

        dPhi = A @ Phi
        return np.concatenate([dy_state, dPhi.flatten()])

    return dy_state

class EKF:
    def __init__(self, n_states: int = 9):
        self.n = n_states
        self.I = np.eye(n_states)

    def run(self, obs, X_0, x_0, P0, Rk, Q_PSD, options):

        print("Initializing EKF with DMC...")
        
        # --- Initialization ---
        coeffs = options['coeffs']
        abs_tol = options['abs_tol']
        rel_tol = options['rel_tol']
        dt_max = options.get('dt_max', 60.0) 
        bootstrap_steps = options.get('bootstrap_steps', 0)
        
        mu, _, _, B_mat = coeffs

        # 1. Setup State Vector
        X_curr = X_0.copy()
        
        # 2. Setup Deviation Vector
        x_dev = np.zeros(self.n)
        if len(x_0) == self.n:
            x_dev = x_0.copy()

        # 3. Setup Covariance
        P = P0.copy()

        # DMC Noise Mapping Matrix (process noise affects acceleration)
        B_noise = np.zeros((9, 3))
        B_noise[6:9, :] = np.eye(3)

        # Storage
        _P, _state, _x = [], [], []
        _w_terms = [] # <--- NEW: Explicitly storing the 'w' (accel) terms
        _prefit_res, _postfit_res = [], []
        _nis_hist = []
        
        t_prev = 0 
        
        # --- Measurement Loop ---
        for k in range(1, len(obs)):
            meas_row = obs.iloc[k]
            t_curr = meas_row['Time(s)']
            
            print_progress(k, len(obs))

            # -------------------------------------------------------
            # 1. PROPAGATION
            # -------------------------------------------------------
            t_internal = t_prev
            
            while t_internal < t_curr:
                h = min(dt_max, t_curr - t_internal)
                
                # A. Propagate Reference
                sol_step = solve_ivp(
                    dmc_ode_wrapper, 
                    (t_internal, t_internal + h), 
                    X_curr,
                    args=(coeffs,),
                    rtol=rel_tol, atol=abs_tol
                )
                X_curr = sol_step.y[:, -1] 

                # B. Linearize
                r_vec = X_curr[0:3]
                norm_r = np.linalg.norm(r_vec)
                R3 = norm_r**3
                R5 = norm_r**5
                G_grav = (3 * mu / R5) * np.outer(r_vec, r_vec) - (mu / R3) * np.eye(3)
                
                A_mat = np.zeros((9, 9))
                A_mat[0:3, 3:6] = np.eye(3)
                A_mat[3:6, 6:9] = np.eye(3)
                A_mat[3:6, 0:3] = G_grav
                A_mat[6:9, 6:9] = -B_mat # DMC decay
                
                Phi_step, Q_step = compute_van_loan(A_mat, B_noise, Q_PSD, h)
                
                # C. Propagate Deviation & Covariance
                x_dev = Phi_step @ x_dev
                P = Phi_step @ P @ Phi_step.T + Q_step
                
                t_internal += h
            
            # -------------------------------------------------------
            # 2. MEASUREMENT UPDATE
            # -------------------------------------------------------
            station_idx = int(meas_row['Station_ID']) - 1
            lat, lon = stations_ll[station_idx]
            Rs, Vs = get_gs_eci_state(lat, lon, t_curr, init_theta=np.deg2rad(122))
            
            y_pred_ref = compute_rho_rhodot(X_curr[0:6], np.concatenate([Rs, Vs]))
            y_obs = np.array([meas_row['Range(km)'], meas_row['Range_Rate(km/s)']])
            
            prefit_res_ref = y_obs - y_pred_ref
            
            H_spatial = compute_H_matrix(X_curr[0:3], X_curr[3:6], Rs, Vs)
            H = np.hstack([H_spatial, np.zeros((2, 3))])
            
            innovation = prefit_res_ref - H @ x_dev
            
            S = H @ P @ H.T + Rk
            K = (np.linalg.solve(S, H @ P)).T
            
            dx = K @ innovation
            x_dev = x_dev + dx
            
            IKH = self.I - K @ H
            P = IKH @ P @ IKH.T + K @ Rk @ K.T
            
            nis = innovation.T @ np.linalg.solve(S, innovation)
            postfit_res = prefit_res_ref - H @ x_dev

            # -------------------------------------------------------
            # 3. RECTIFICATION
            # -------------------------------------------------------
            if k >= bootstrap_steps:
                X_curr[0:9] = X_curr[0:9] + x_dev
                x_dev = np.zeros(self.n)

            # -------------------------------------------------------
            # 4. LOGGING
            # -------------------------------------------------------
            X_total = X_curr.copy()
            # If not rectifying, we must add dev to ref to get total estimate
            if k < bootstrap_steps:
                X_total = X_total + x_dev
            
            _x.append(x_dev.copy())
            _state.append(X_total[0:6].copy())
            
            # CAPTURE THE W TERMS (Last 3 states)
            w_current = X_total[6:9].copy()
            _w_terms.append(w_current)
            
            _P.append(P.copy())
            _prefit_res.append(prefit_res_ref.copy())
            _postfit_res.append(postfit_res.copy())
            _nis_hist.append(nis)
            
            t_prev = t_curr

        return FilterResults(_x, _P, _state, _prefit_res, _postfit_res, _nis_hist, accel_hist=_w_terms)